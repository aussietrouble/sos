#Monotonicity pattern Regression
#Sabyasachi Chatterjee
##################################
# Import Rmosek
if (!require("Rmosek")) {
  stop ("Rmosek not installed.")
}
################################
# Convex Programming using Rmosek CQP
#---------------------------------------
#The following program takes in a design matrix X, data y (generated by
#an additive increasing/decreasing model with some given pattern)
# and a tuning parameter lambda. It outputs a list with 4 components.
# First component is the solution status. 
#Second and Third components are matrices with the increasing and decreasing fits. Each column of these
#matrices give fits to each of the functions. The output fits are sorted according
#to the design points for each variable.
#The fourth component is a guess at the pattern.
monotone.pattern.regression <- function (X, y, lambda) {
last <- function (x) {
  # x is a sequence
  return (x[length(x)])
}

# [Program variables]
# fitted increasing values: f_1,..,f_n.
# fitted decreasing values: g_1,..,g_n.
# auxiliary variables: r_i = y_i - (f_i + g_i)
# objective replacement: t
f.index <- seq(1, n*p) 
g.index <- last(f.index) + seq(1, n*p) 
r.index <- last(g.index) + seq(1, n) 
t.index <- last(r.index) + 1 
num.vars <- t.index

# Helpers: Selecting variables
# (Think of f_ij as the (i,j)th entry of an n by p matrix.)
f.select.row <- lapply(1:n, function (i) { seq(i*p-p+1, i*p) })
f.select.col <- lapply(1:p, function (j) { seq(j, n*p, p) })
g.select.row <- lapply(1:n, function (i) { last(f.index) + seq(i*p-p+1, i*p) })
g.select.col <- lapply(1:p, function (j) { last(f.index) + seq(j, n*p, p) })
# Set up the program
isopattern.regression <- list(sense = "min")

# Objective: t = sqrt(sum((y-z)^2))
# Note that MSE = (1/n) * (t^2).
isopattern.regression$c <- c(rep(0, 2*n*p + n), 1)

# Affine constraint 1: auxiliary variables [no cost]
# r_i = y_i - sum_j(f_ij + g_ij)
A1 <- Matrix(0, nrow = n, ncol = num.vars)
for (i in 1:n) {
  A1[i, f.select.row[[i]]] <- 1
  A1[i, g.select.row[[i]]] <- 1
  A1[i, r.index[i]] <- 1
}

A2 <- Matrix(0, nrow = 2*(n-1)*p, ncol = num.vars)
for (j in 1:p) {
  # take the ordering (for sorting and putting back in order)
  ord <- order(X[, j])
  # the following sequence x is sorted
  x <- X[ord, j]
  diag.f <- bandSparse(n-1, n, c(0, 1), list(rep(-1, n-1), rep(1, n-1)))
  diag.g <- -diag.f
  rows.f <- 2*(n-1)*(j-1) + seq(1, n-1)
  rows.g <- 2*(n-1)*(j-1) + (n-1) + seq(1, n-1)
  A2[rows.f, f.select.col[[j]]] <- diag.f[, invPerm(ord)]
  A2[rows.g, g.select.col[[j]]] <- diag.g[, invPerm(ord)]
}
  
  
# Affine constraint 3: identifiability via centering [2*p equalities]
A3 <- Matrix(0, nrow = 2*p, ncol = num.vars)
for (j in 1:p) {
  A3[j, f.select.col[[j]]] <- 1
  A3[p+j, g.select.col[[j]]] <- 1
}

#Penalty constraints on each variable
A4 <- Matrix(0, nrow = 1, ncol = num.vars)
for (j in 1:p) {
  ord <- order(X[, j])
  A4[1,f.select.col[[j]][ord[n]]] = 1
  A4[1,f.select.col[[j]][ord[1]]] = -1
  A4[1,g.select.col[[j]][ord[n]]] = -1
  A4[1,g.select.col[[j]][ord[1]]] = 1
}
isopattern.regression$A <- rBind(A1,A2,A3,A4)

isopattern.regression$bc <- rbind(
  blc = c(y, rep(0, 2*(n-1)*p), rep(0, 2*p), 0),
  buc = c(y, rep(Inf, 2*(n-1)*p), rep(0, 2*p), lambda)
)

# Empty constraints on the program variables
isopattern.regression$bx <- rbind(
  blx = c(rep(-Inf, 2*n*p + n), 0),
  bux = rep(Inf, 2*n*p + n + 1)
)

# Quadratic objective: mean squared error
# (replaced by an equivalent conic constraint)
isopattern.regression$cones <- cbind(
  list("QUAD", c(t.index,r.index))
)

# Solve the program using Rmosek!
r <- mosek(isopattern.regression)

status <- r$sol$int$solsta 
fhat = r$sol$itr$xx[f.index]
ghat = r$sol$itr$xx[g.index]
fhatmat = matrix(fhat,n,p,byrow = T)
ghatmat = matrix(ghat,n,p,byrow = T)
#fit = fhat + ghat
#MSE <- (1/n) * (r$sol$itr$xx[t.index]^2)

for (j in 1:p){
  fhatmat[,j] = fhatmat[,j][order(X[,j])]
  ghatmat[,j] = ghatmat[,j][order(X[,j])]
}
#f1hat = fhat[f.select.col[[1]]]
#f2hat = fhat[f.select.col[[2]]]
#f3hat = fhat[f.select.col[[3]]]
#f4hat = fhat[f.select.col[[4]]]

#f1hat = f1hat[order(X[,1])]
#f2hat = f2hat[order(X[,2])]
#f3hat = f3hat[order(X[,3])]
#f4hat = f4hat[order(X[,4])]


#g1hat = ghat[g.select.col[[1]] - last(f.index)]
#g2hat = ghat[g.select.col[[2]] - last(f.index)]
#g3hat = ghat[g.select.col[[3]] - last(f.index)]
#g4hat = ghat[g.select.col[[4]] - last(f.index)]

#g1hat = g1hat[order(X[,1])]
#g2hat = g2hat[order(X[,2])]
#g3hat = g3hat[order(X[,3])]
#g4hat = g4hat[order(X[,4])]
ans = list()
ans[[1]] = status
ans[[2]] = fhatmat
ans[[3]] = ghatmat
ans[[4]] = rep(-1,p)
for (j in 1:p){
  if (fhatmat[n,j] - fhatmat[1,j] > ghatmat[1,j] - ghatmat[n,j]){
    ans[[4]][j] = 1
  }
}
return(ans)
}

#####################Experiments######################
##########Create a repository of increasing functions########
f <- list()
f[[1]] = function(x){
  #return(2*x)
  return(x^3 + 1)
}
f[[2]] = function(x){
  ifelse ((x > 0),x^2,0)
}
f[[3]] = function(w){
  y = abs(w)
  ans = y^{0.2}
  ans = (w/y)*ans
  return(ans)
}

f[[4]] = function(w){
  ans = w + abs(w)
  return(ans/2)
}

f[[5]] = function(w){
  ans = floor(4*w)
  return(ans)
}

f[[6]] = function(w){
  ans = exp(w)
  return(ans)
}

f[[7]] = function(w){
  ans = sin((pi/2)*w)
  return(ans)
}

f[[8]] = function(w){
  ans = log(w + 1.2)
  return(ans)
}
#x = seq(-1,1,by = 0.1)
#plot(x,f[[8]](x))
################################################
#Create a true pattern by allocating random signs
bern = runif(length(f),-1,1)
truepattern = sign(bern)
################################################
set.seed(690)
lambda = 15
n <- 200
p = 8
sigma = 1/3
X <- Matrix(runif(n*p, -1, 1), nrow=n) 
#Simulate Data
y <- rowSums(sapply(1:p, function (j){
  f_j <- sapply(X[,j],f[[j]])
  f_j = truepattern[j]*f_j
  return (f_j - mean(f_j))
})) 
y <- y + rnorm(n, 0, sigma)
################################################
solution = monotone.pattern.regression(X,y,lambda)
#Solution is a list with 4 components.
################################################
#function to plot the fit to the jth sequence or function
#Use this function to just visualize any of the functions and 
#its increasing/decreasing fits.
plotfn = function(j){
  x = sort(X[,j])
  ord = order(X[,j])
  y = truepattern[j]*f[[j]](x)
  y = y - rep(mean(y),n)
  plot(x,y, main = "Increasing and Decreasing Component")
  lines(x,solution[[2]][,j], lwd = 2, col = "green")
  lines(x,solution[[3]][,j], lwd = 2, col = "blue")
}
##################################################
#Comments: We have to automate the process of slowly increasing 
#lambda from 0. When lambda = 0 all the fits are zero. As we increase 
#lambda, the correct pattern seems to pop out for all the variables.
##################################################